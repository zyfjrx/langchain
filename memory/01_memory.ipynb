{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ChatMessageHistory(基础)",
   "id": "b42ae2691ccd1eb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T07:38:45.413562Z",
     "start_time": "2025-08-06T07:38:45.130384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#1.导入相关包\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "#2.实例化ChatMessageHistory对象\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "# 3.添加UserMessage\n",
    "history.add_user_message(\"hi!\")\n",
    "\n",
    "# 4.添加AIMessage\n",
    "history.add_ai_message(\"whats up?\")\n",
    "\n",
    "# 5.返回存储的所有消息列表\n",
    "history.messages"
   ],
   "id": "4922f6cee65fa17c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='whats up?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T07:41:31.843390Z",
     "start_time": "2025-08-06T07:41:29.589424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_ai_message(\"我是一个无所不能的小智\")\n",
    "history.add_user_message(\"你好，我叫小明，请介绍一下你自己\")\n",
    "history.add_user_message(\"我是谁呢？\")\n",
    "\n",
    "# print(history.messages)  #返回List[BaseMessage]类型\n",
    "# 创建LLM\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(\n",
    "    model=\"qwen-plus\",\n",
    "    api_key=os.getenv('DASHSCOPE_API_KEY'),\n",
    "    base_url=os.getenv('DASHSCOPE_BASE_URL')\n",
    ")\n",
    "\n",
    "llm.invoke(history.messages)"
   ],
   "id": "8f4d71aaab19a7cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好小明！我是通义千问，英文名Qwen，是一个超厉害的AI助手。我可以帮你写故事、写邮件、做计算，还能陪你聊天解闷。你可以问我任何问题，或者让我帮你完成各种任务。虽然我不能说自己是无所不能啦，但我真的很擅长很多事情哦！说说看你想让我帮你做什么呢？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 42, 'total_tokens': 117, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-f82665db-4388-9f08-b012-3154d70de5ec', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--f2fcaa01-5bef-4173-a142-9ed4f1793b2a-0', usage_metadata={'input_tokens': 42, 'output_tokens': 75, 'total_tokens': 117, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ConversationBufferMemory\n",
    "\n",
    "ConversationBufferMemory是一个基础的`对话记忆（Memory）组件`，专门用于按`原始顺序存储`完整的对话历史。它的核心特点是`简单`、`无裁剪`、`无压缩`，适用于需要完整上下文的小规模对话场景。"
   ],
   "id": "4e14d2ea4d45c6c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用PromptTemplate",
   "id": "9b7e3ffeb3c0b2fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T08:09:28.034664Z",
     "start_time": "2025-08-06T08:09:28.030841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入相关包\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 2.实例化ConversationBufferMemory对象\n",
    "memory = ConversationBufferMemory(return_messages=False)\n",
    "# 3.保存消息到内存中\n",
    "memory.save_context(inputs = {\"input\": \"你好，我是人类\"}, outputs = {\"output\": \"你好，我是AI助手\"})\n",
    "memory.save_context(inputs = {\"input\": \"很开心认识你\"}, outputs = {\"output\": \"我也是\"})\n",
    "\n",
    "# 4.读取内存中消息（返回消息内容的纯文本）\n",
    "print(memory.load_memory_variables({}))\n",
    "print(memory.chat_memory.messages)"
   ],
   "id": "656322f92c7c114d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你好，我是人类\\nAI: 你好，我是AI助手\\nHuman: 很开心认识你\\nAI: 我也是'}\n",
      "[HumanMessage(content='你好，我是人类', additional_kwargs={}, response_metadata={}), AIMessage(content='你好，我是AI助手', additional_kwargs={}, response_metadata={}), HumanMessage(content='很开心认识你', additional_kwargs={}, response_metadata={}), AIMessage(content='我也是', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 注意：\n",
    "- 不管inputs、outputs的key用什么名字，都认为inputs的key是human，outputs的key是AI。\n",
    "- 打印的结果的json数据的key，默认是“history”。可以通过ConversationBufferMemory的`memory_key`属性修改。"
   ],
   "id": "b0b53282d204a836"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T08:09:43.534114Z",
     "start_time": "2025-08-06T08:09:43.531067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入相关包\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 2.实例化ConversationBufferMemory对象\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# 3.保存消息到内存中\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
    "\n",
    "# 4.读取内存中消息（返回消息）\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "# 5.读取内存中消息( 访问原始消息列表)\n",
    "print(memory.chat_memory.messages)"
   ],
   "id": "1c80d2113e484aec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='whats up', additional_kwargs={}, response_metadata={})]}\n",
      "[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='whats up', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 使用PromptTemplate结合LLM使用",
   "id": "7748e10f361626f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T07:49:16.959099Z",
     "start_time": "2025-08-06T07:49:15.314136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 创建提示\n",
    "# 有两个输入键：实际输入与来自记忆类的输入 需确保PromptTemplate和ConversationBufferMemory中的键匹配\n",
    "template = \"\"\"你可以与人类对话。\n",
    "\n",
    "当前对话: {history}\n",
    "\n",
    "人类问题: {question}\n",
    "\n",
    "回复:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 创建ConversationBufferMemory\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# 初始化链\n",
    "chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "# 提问\n",
    "res1 = chain.invoke({\"question\": \"我的名字叫Tom\"})\n",
    "print(res1)\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "301ea661c6f16d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我的名字叫Tom', 'history': '', 'text': '你好，Tom！有什么我可以帮你的吗？'}\n",
      "{'history': 'Human: 我的名字叫Tom\\nAI: 你好，Tom！有什么我可以帮你的吗？'}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T07:49:21.356442Z",
     "start_time": "2025-08-06T07:49:20.868250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = chain.invoke({\"question\": \"我的名字是什么?\"})\n",
    "print(res)"
   ],
   "id": "675dd25eb1caced8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我的名字是什么?', 'history': 'Human: 我的名字叫Tom\\nAI: 你好，Tom！有什么我可以帮你的吗？', 'text': '你的名字是Tom！'}\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T07:52:05.314874Z",
     "start_time": "2025-08-06T07:52:03.932617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# 创建提示\n",
    "# 有两个输入键：实际输入与来自记忆类的输入 需确保PromptTemplate和ConversationBufferMemory中的键匹配\n",
    "template = \"\"\"你可以与人类对话。\n",
    "\n",
    "当前对话: {chat_history}\n",
    "\n",
    "人类问题: {question}\n",
    "\n",
    "回复:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 创建ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "# 初始化链\n",
    "chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "# 提问\n",
    "res1 = chain.invoke({\"question\": \"我的名字叫Tom\"})\n",
    "print(str(res1) + \"\\n\")\n",
    "print(memory.load_memory_variables({}))\n",
    "res = chain.invoke({\"question\": \"我的名字是什么?\"})\n",
    "print(res)"
   ],
   "id": "37c7658864c8b19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '我的名字叫Tom', 'chat_history': '', 'text': '你好，Tom！很高兴认识你。有什么我可以帮你的吗？'}\n",
      "\n",
      "{'chat_history': 'Human: 我的名字叫Tom\\nAI: 你好，Tom！很高兴认识你。有什么我可以帮你的吗？'}\n",
      "{'question': '我的名字是什么?', 'chat_history': 'Human: 我的名字叫Tom\\nAI: 你好，Tom！很高兴认识你。有什么我可以帮你的吗？', 'text': '你的名字是Tom！'}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 使用ChatPromptTemplate 和 return_messages",
   "id": "6f520bc3b9ce99b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T08:36:39.375757Z",
     "start_time": "2025-08-06T08:36:37.877294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入相关包\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder,ChatPromptTemplate,HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "# 3.创建Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"你是一个与人类对话的机器人。\"),\n",
    "    MessagesPlaceholder(variable_name='history'),\n",
    "    (\"human\",\"问题：{question}\")\n",
    "])\n",
    "\n",
    "# 4.创建Memory\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "# 5.创建LLMChain\n",
    "llm_chain = LLMChain(prompt=prompt,llm=llm, memory=memory)\n",
    "\n",
    "# 6.调用LLMChain\n",
    "res1 = llm_chain.invoke({\"question\": \"中国首都在哪里？\"})\n",
    "print(res1,end=\"\\n\\n\")\n",
    "\n",
    "res2 = llm_chain.invoke({\"question\": \"我刚刚问了什么\"})\n",
    "print(res2)\n"
   ],
   "id": "cdc59b12409e4588",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '中国首都在哪里？', 'history': [HumanMessage(content='中国首都在哪里？', additional_kwargs={}, response_metadata={}), AIMessage(content='中国首都是**北京**。北京是中国的政治、文化和国际交往中心，也是世界著名古都之一。', additional_kwargs={}, response_metadata={})], 'text': '中国首都是**北京**。北京是中国的政治、文化和国际交往中心，也是世界著名古都之一。'}\n",
      "\n",
      "{'question': '我刚刚问了什么', 'history': [HumanMessage(content='中国首都在哪里？', additional_kwargs={}, response_metadata={}), AIMessage(content='中国首都是**北京**。北京是中国的政治、文化和国际交往中心，也是世界著名古都之一。', additional_kwargs={}, response_metadata={}), HumanMessage(content='我刚刚问了什么', additional_kwargs={}, response_metadata={}), AIMessage(content='你刚刚问的是：“中国首都在哪里？”', additional_kwargs={}, response_metadata={})], 'text': '你刚刚问的是：“中国首都在哪里？”'}\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ConversationChain\n",
    "\n",
    "ConversationChain提供了包含AI角色和人类角色的对话摘要格式，这个对话格式和记忆机制结合得非常紧密。\n",
    "\n",
    "ConversationChain实际上是就是对`ConversationBufferMemory`和`LLMChain`进行了封装，并且提供一个默认格式的提示词模版（我们也可以不用），从而简化了初始化ConversationBufferMemory的步骤。\n",
    "\n",
    "举例1：使用PromptTemplate"
   ],
   "id": "3f8279d5e7040f85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T08:43:18.097150Z",
     "start_time": "2025-08-06T08:43:15.268927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "# 初始化大模型\n",
    "llm=ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    base_url=os.getenv('OPENAI_BASE_URL')\n",
    ")\n",
    "template = \"\"\"以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的具体细节。如果AI不知道问题的答案，它会真诚地表示不知道。\n",
    "\n",
    "当前对话：\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# memory = ConversationBufferMemory()\n",
    "#\n",
    "# conversation = LLMChain(\n",
    "#     llm=llm,\n",
    "#     prompt = prompt,\n",
    "#     memory=memory,\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "chain = ConversationChain(llm = llm, prompt = prompt,verbose=True)\n",
    "\n",
    "\n",
    "chain.invoke({\"input\":\"你好，你的名字叫小智\"})  #注意，chain中的key必须是input，否则会报错"
   ],
   "id": "657a5df5ad782974",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的具体细节。如果AI不知道问题的答案，它会真诚地表示不知道。\n",
      "\n",
      "当前对话：\n",
      "\n",
      "Human: 你好，你的名字叫小智\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '你好，你的名字叫小智',\n",
       " 'history': '',\n",
       " 'response': '你好！是的，我叫小智，很高兴认识你！有什么我可以帮助你的吗？'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T08:43:24.095693Z",
     "start_time": "2025-08-06T08:43:22.143471Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke({\"input\":\"你好，你叫什么名字？\"})",
   "id": "6569c86368b31825",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的具体细节。如果AI不知道问题的答案，它会真诚地表示不知道。\n",
      "\n",
      "当前对话：\n",
      "Human: 你好，你的名字叫小智\n",
      "AI: 你好！是的，我叫小智，很高兴认识你！有什么我可以帮助你的吗？\n",
      "Human: 你好，你叫什么名字？\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '你好，你叫什么名字？',\n",
       " 'history': 'Human: 你好，你的名字叫小智\\nAI: 你好！是的，我叫小智，很高兴认识你！有什么我可以帮助你的吗？',\n",
       " 'response': '你好！我叫小智，很高兴再次见到你！请问有什么我可以帮助你的吗？'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T08:48:10.041374Z",
     "start_time": "2025-08-06T08:47:59.526420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入所需的库\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "\n",
    "# 3.初始化对话链\n",
    "conv_chain = ConversationChain(llm=llm)\n",
    "\n",
    "# 4.进行对话\n",
    "resut1 = conv_chain.invoke(input=\"小明有1只猫\")\n",
    "# print(resut1)\n",
    "resut2 = conv_chain.invoke(input=\"小刚有2只狗\")\n",
    "# print(resut2)\n",
    "resut3 = conv_chain.invoke(input=\"小明和小刚一共有几只宠物?\")\n",
    "print(resut3)"
   ],
   "id": "8ff5c068337f4520",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '小明和小刚一共有几只宠物?', 'history': 'Human: 小明有1只猫\\nAI: 小明的猫是什么品种呢？猫咪的颜色和性别是怎样的？另外，小明平时怎么照顾这只猫？比如，给它喂什么食物，常常带它去哪里玩？猫咪也有很多有趣的行为，比如喜欢打盹、抓东西或者和人互动，你觉得小明的猫有什么特别的地方吗？\\nHuman: 小刚有2只狗\\nAI: 小刚的狗狗们听起来很可爱！它们是什么品种呢？狗狗的名字是什么？以及它们的性别和年龄又是怎样的？小刚平时是怎么照顾这两只狗的？比如，给它们提供什么样的食物，定期带它们去散步、游玩或者参加训练课程吗？狗狗的性格也很有趣，有的活泼好动，有的则比较温顺。你觉得小刚的狗有什么特别之处？它们之间有没有有趣的互动呢？', 'response': '小明有1只猫，小刚有2只狗，所以他们一共有3只宠物！这真是一群让人愉快的小伙伴。你觉得小明和小刚的宠物们会不会互动呢？比如一起玩或者一起出去散步？这一定会很有趣！'}\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###  ConversationBufferWindowMemory\n",
    "\n",
    "在了解了ConversationBufferMemory记忆类后，我们知道了它能够无限的将历史对话信息填充到History中，从而给大模型提供上下文的背景。但这会`导致内存量十分大`，并且`消耗的token是非常多`的，此外，每个大模型都存在最大输入的Token限制。\n",
    "\n",
    "我们发现，过久远的对话数据往往并不能对当前轮次的问答提供有效的信息，LangChain 给出的解决方式是：`ConversationBufferWindowMemory`模块。该记忆类会`保存一段时间内对话交互`的列表，`仅使用最近 K 个交互`。这样就使缓存区不会变得太大。"
   ],
   "id": "3b9f2a58b9dd28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T08:50:40.860557Z",
     "start_time": "2025-08-06T08:50:40.856937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入相关包\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# 2.实例化ConversationBufferWindowMemory对象，设定窗口阈值\n",
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "# 3.保存消息\n",
    "memory.save_context({\"input\": \"你好\"}, {\"output\": \"怎么了\"})\n",
    "memory.save_context({\"input\": \"你是谁\"}, {\"output\": \"我是AI助手\"})\n",
    "memory.save_context({\"input\": \"你的生日是哪天？\"}, {\"output\": \"我不清楚\"})\n",
    "# 4.读取内存中消息（返回消息内容的纯文本）\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "85ec8db3007fcd73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你是谁\\nAI: 我是AI助手\\nHuman: 你的生日是哪天？\\nAI: 我不清楚'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/88/h2503n817r15dm_yghgn_vcm0000gn/T/ipykernel_39445/2600179964.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=2)\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T08:51:41.358660Z",
     "start_time": "2025-08-06T08:51:41.355033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入相关包\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# 2.实例化ConversationBufferWindowMemory对象，设定窗口阈值\n",
    "memory = ConversationBufferWindowMemory(k=2, return_messages=True)\n",
    "# 3.保存消息\n",
    "memory.save_context({\"input\": \"你好\"}, {\"output\": \"怎么了\"})\n",
    "memory.save_context({\"input\": \"你是谁\"}, {\"output\": \"我是AI助手小智\"})\n",
    "memory.save_context({\"input\": \"初次对话，你能介绍一下你自己吗？\"}, {\"output\": \"当然可以了。我是一个无所不能的小智。\"})\n",
    "# 4.读取内存中消息（返回消息内容的纯文本）\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "dbe609f9e6dce5e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='你是谁', additional_kwargs={}, response_metadata={}), AIMessage(content='我是AI助手小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='初次对话，你能介绍一下你自己吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='当然可以了。我是一个无所不能的小智。', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T08:55:34.048557Z",
     "start_time": "2025-08-06T08:55:25.494308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "# 1.导入相关包\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "# 2.定义模版\n",
    "template = \"\"\"以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
    "\n",
    "当前对话：\n",
    "{history}\n",
    "Human: {question}\n",
    "AI:\"\"\"\n",
    "\n",
    "# 3.定义提示词模版\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "# 5.实例化ConversationBufferWindowMemory对象，设定窗口阈值\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "# 6.定义LLMChain\n",
    "conversation_with_summary = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 7.执行链（第一次提问）\n",
    "respon1 = conversation_with_summary.invoke({\"question\":\"你好，我是孙小空\"})\n",
    "# print(respon1)\n",
    "# 8.执行链（第二次提问）\n",
    "respon2 =conversation_with_summary.invoke({\"question\":\"我还有两个师弟，一个是猪小戒，一个是沙小僧\"})\n",
    "# print(respon2)\n",
    "# 9.执行链（第三次提问）\n",
    "respon3 =conversation_with_summary.invoke({\"question\":\"我今年高考，竟然考上了1本\"})\n",
    "# print(respon3)\n",
    "# 10.执行链（第四次提问）\n",
    "respon4 =conversation_with_summary.invoke({\"question\":\"我叫什么？\"})\n",
    "print(respon4)"
   ],
   "id": "a23501609da3d5f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "\n",
      "当前对话：\n",
      "\n",
      "Human: 你好，我是孙小空\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "\n",
      "当前对话：\n",
      "Human: 你好，我是孙小空\n",
      "AI: 你好，孙小空！很高兴认识你！你今天怎么样？有什么想聊的或者想了解的话题吗？\n",
      "Human: 我还有两个师弟，一个是猪小戒，一个是沙小僧\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "\n",
      "当前对话：\n",
      "Human: 我还有两个师弟，一个是猪小戒，一个是沙小僧\n",
      "AI: 哇，听起来你们的名字都很有趣！猪小戒和沙小僧有什么特别的故事或者特点吗？你们之间有些什么样的互动呢？\n",
      "Human: 我今年高考，竟然考上了1本\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m以下是人类与AI之间的友好对话描述。AI表现得很健谈，并提供了大量来自其上下文的具体细节。如果AI不知道问题的答案，它会表示不知道。\n",
      "\n",
      "当前对话：\n",
      "Human: 我今年高考，竟然考上了1本\n",
      "AI: 太棒了！恭喜你考上了本科！这是一个重要的里程碑，你一定付出了很多努力。你打算学什么专业呢？或者有什么未来的计划吗？\n",
      "Human: 我叫什么？\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'question': '我叫什么？', 'history': 'Human: 我今年高考，竟然考上了1本\\nAI: 太棒了！恭喜你考上了本科！这是一个重要的里程碑，你一定付出了很多努力。你打算学什么专业呢？或者有什么未来的计划吗？', 'text': '抱歉，我不知道你叫什么名字。不过我很高兴能和你聊天！如果你愿意，告诉我你的名字或者其他任何事情。'}\n"
     ]
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
