{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-05T02:47:21.215537Z",
     "start_time": "2025-08-05T02:47:14.813151Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "# 硬编码 API Key 和模型参数\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  # 明文暴露密钥\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 调用示例\n",
    "response = llm.invoke(\"解释神经网络原理\")\n",
    "print(type(response))\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "神经网络是一种模拟人脑神经元工作方式的计算模型，用于处理复杂的数据和执行机器学习任务。其基本原理可以从以下几个方面进行解释：\n",
      "\n",
      "### 1. **基本结构**\n",
      "神经网络由多个层次组成，通常包括：\n",
      "- **输入层**：接收外部输入数据。\n",
      "- **隐藏层**：一个或多个中间层，进行特征提取和变换。\n",
      "- **输出层**：生成最终的预测结果或分类。\n",
      "\n",
      "每一层由多个“神经元”组成，神经元是网络的基本计算单元。\n",
      "\n",
      "### 2. **神经元**\n",
      "每个神经元接收来自前一层的输入信号，并执行以下步骤：\n",
      "- **加权求和**：将输入信号与权重相乘并求和，同时加上一个偏置（bias）项。\n",
      "- **激活函数**：通过激活函数处理加权求和的结果，决定神经元的输出。常见的激活函数包括Sigmoid、ReLU（Rectified Linear Unit）和Tanh等。\n",
      "\n",
      "### 3. **前向传播**\n",
      "在前向传播过程中，输入数据从输入层经过隐藏层最终到达输出层。每一层的输出作为下一层的输入，直到生成最终结果。\n",
      "\n",
      "### 4. **损失函数**\n",
      "神经网络的目标是最小化预测结果与真实值之间的差距，这个差距用损失函数来衡量。常见的损失函数有均方误差（MSE）、交叉熵等。\n",
      "\n",
      "### 5. **反向传播**\n",
      "为了更新网络中的权重和偏置，神经网络使用反向传播算法：\n",
      "- **计算梯度**：通过链式法则计算损失函数相对于每个权重和偏置的梯度。\n",
      "- **更新权重**：使用梯度下降或其他优化算法（如Adam、RMSProp等）来更新权重和偏置，以减少损失。\n",
      "\n",
      "### 6. **训练过程**\n",
      "神经网络的训练过程包括多个步骤：\n",
      "- **初始化**：随机初始化权重和偏置。\n",
      "- **迭代训练**：通过多次前向传播和反向传播，不断调整权重和偏置，直到损失函数收敛或达到预设的迭代次数。\n",
      "\n",
      "### 7. **泛化能力**\n",
      "训练完成后，神经网络需要具备良好的泛化能力，能够对未见过的数据进行准确预测。为此，通常会使用技巧如交叉验证、正则化、Dropout等来防止过拟合。\n",
      "\n",
      "### 总结\n",
      "神经网络通过模拟生物神经元的连接和工作方式，利用多层结构和非线性激活函数来学习复杂的模式。其强大的表示能力和灵活性使其在图像识别、自然语言处理、语音识别等众多领域得到了广泛应用。\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1 对话模型Message的使用",
   "id": "642373eee14dc1e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T02:56:59.355812Z",
     "start_time": "2025-08-05T02:56:59.352281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage,ChatMessage\n",
    "\n",
    "messages = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "            HumanMessage(content=\"你好，请你介绍一下你自己\"),\n",
    "            ChatMessage(role=\"assistant\", content=\"我叫小助手，是一个智能小助手，你可以向我提问任何问题\", ),\n",
    "            ]\n",
    "\n",
    "print(messages)"
   ],
   "id": "8eca5fba91537a85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一位乐于助人的智能小助手', additional_kwargs={}, response_metadata={}), HumanMessage(content='你好，请你介绍一下你自己', additional_kwargs={}, response_metadata={}), ChatMessage(content='我叫小助手，是一个智能小助手，你可以向我提问任何问题', additional_kwargs={}, response_metadata={}, role='assistant')]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T05:51:28.807935Z",
     "start_time": "2025-08-05T05:51:25.557595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "# 硬编码 API Key 和模型参数\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  # 明文暴露密钥\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7\n",
    ")\n",
    "messages = [SystemMessage(content=\"你是一位乐于助人的智能小助手，你的名字叫小智\"),\n",
    "            HumanMessage(content=\"猫王是猫吗\"),\n",
    "            HumanMessage(content=\"你叫什么名字？\"),]\n",
    "# 调用示例\n",
    "# response1 = llm.stream(messages)\n",
    "# print(response1)\n",
    "# response2 = llm.stream(\"你叫什么名字\")\n",
    "# print(response2.content)\n",
    "# 流式调用LLM获取响应\n",
    "print(\"开始流式输出：\")\n",
    "for chunk in llm.stream(messages):\n",
    "    # 逐个打印内容块\n",
    "    print(chunk.content, end=\"\", flush=True) # 刷新缓冲区 (无换行符，缓冲区未刷新，内容可能不会立即显示)\n",
    "\n",
    "print(\"\\n流式输出结束\")"
   ],
   "id": "6b8728e027eed80f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始流式输出：\n",
      "我叫小智，很高兴为你服务！有什么我可以帮助你的吗？\n",
      "流式输出结束\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 对话模型的调用",
   "id": "8ac54d4a177a665a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T03:18:02.933844Z",
     "start_time": "2025-08-05T03:17:59.836545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "# 硬编码 API Key 和模型参数\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  # 明文暴露密钥\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7\n",
    ")\n",
    "messages = [SystemMessage(content=\"你是一位乐于助人的智能小助手，你的名字叫小智\"),\n",
    "            HumanMessage(content=\"Langchain是什么？包含哪些知识\")]\n",
    "print(\"开始流式输出：\")\n",
    "for chunk in llm.stream(messages):\n",
    "    # 逐个打印内容块\n",
    "    print(chunk.content, end=\"\", flush=True) # 刷新缓冲区 (无换行符，缓冲区未刷新，内容可能不会立即显示)\n",
    "\n",
    "print(\"\\n流式输出结束\")"
   ],
   "id": "cc88227d518de4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始流式输出：\n",
      "LangChain 是一个用于构建与语言模型（如 GPT-3、GPT-4 等）交互的应用程序的框架。它旨在帮助开发者更方便地使用语言模型，构建复杂的自然语言处理（NLP）和对话系统。LangChain 提供了一系列工具和组件，可以用于不同的应用场景。\n",
      "\n",
      "LangChain 包含的知识和功能主要包括：\n",
      "\n",
      "1. **链式模型调用**：允许用户将多个语言模型或工具组合在一起，以形成逻辑链，从而实现更复杂的任务。\n",
      "\n",
      "2. **文档处理**：支持从多种数据源（如文本文件、数据库、API 等）提取和处理信息，方便与语言模型结合使用。\n",
      "\n",
      "3. **代理和工具**：提供代理的概念，使模型能够根据上下文进行决策，调用外部工具或 API。\n",
      "\n",
      "4. **上下文管理**：帮助管理和存储对话上下文，以便更好地跟踪用户输入和模型响应。\n",
      "\n",
      "5. **自定义组件**：允许开发者创建自定义的链、代理和工具，以满足特定需求。\n",
      "\n",
      "6. **集成支持**：支持与多种外部 API 和服务的集成，提升应用的功能性。\n",
      "\n",
      "7. **性能优化**：提供一些机制来提高模型调用的效率和性能。\n",
      "\n",
      "通过使用 LangChain，开发者可以更高效地构建强大的语言模型应用，适用于聊天机器人、内容生成、信息检索等多种场景。\n",
      "流式输出结束\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 同步调用与异步调用",
   "id": "c76317c6e445b02f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T05:10:11.498744Z",
     "start_time": "2025-08-05T05:10:01.470946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "def call_model():\n",
    "    # 模拟同步API调用\n",
    "    print(\"开始调用模型...\")\n",
    "    time.sleep(5)  # 模拟调用等待,单位：秒\n",
    "    print(\"模型调用完成。\")\n",
    "\n",
    "def perform_other_tasks():\n",
    "    # 模拟执行其他任务\n",
    "    for i in range(5):\n",
    "        print(f\"执行其他任务 {i + 1}\")\n",
    "        time.sleep(1)  # 单位：秒\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    call_model()\n",
    "    perform_other_tasks()\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    return f\"总共耗时：{total_time}秒\"\n",
    "\n",
    "# 运行同步任务并打印完成时间\n",
    "main_time = main()\n",
    "print(main_time)"
   ],
   "id": "5534159069fd0432",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始调用模型...\n",
      "模型调用完成。\n",
      "执行其他任务 1\n",
      "执行其他任务 2\n",
      "执行其他任务 3\n",
      "执行其他任务 4\n",
      "执行其他任务 5\n",
      "总共耗时：10.019119262695312秒\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T05:18:52.253091Z",
     "start_time": "2025-08-05T05:18:47.244926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def async_call(llm):\n",
    "    await asyncio.sleep(5)  # 模拟异步操作\n",
    "    print(\"异步调用完成\")\n",
    "\n",
    "async def perform_other_tasks():\n",
    "    await asyncio.sleep(5)  # 模拟异步操作\n",
    "    print(\"其他任务完成\")\n",
    "\n",
    "async def run_async_tasks():\n",
    "    start_time = time.time()\n",
    "    await asyncio.gather(\n",
    "        async_call(None),  # 示例调用，替换None为模拟的LLM对象\n",
    "        perform_other_tasks()\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    return f\"总共耗时：{end_time - start_time}秒\"\n",
    "\n",
    "# # 正确运行异步任务的方式\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 使用 asyncio.run() 来启动异步程序\n",
    "#     result = asyncio.run(run_async_tasks())\n",
    "#     print(result)\n",
    "\n",
    "\n",
    "# 在 Jupyter 单元格中直接调用\n",
    "result = await run_async_tasks()\n",
    "print(result)"
   ],
   "id": "5305855745e4d514",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "异步调用完成\n",
      "其他任务完成\n",
      "总共耗时：5.002461910247803秒\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
